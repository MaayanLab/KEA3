{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlap GMT\n",
    "The purpose of this Jupyter Notebook is to rank the kinase-target gene sets by their amount of co-occurence and to store this information in a separate GMT file. This code will be heavily borrowed from the work of Damon Pham, who has written code to perform this task with other libraries. The GMT file containing the kinases and gene sets will be the Combined GMT file created as a culmination of seven databases containing information regarding kinase-target interactions. \n",
    "\n",
    "Date created: 6/27/17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages Needed to Run Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Input: library file from Enrichr. Output: transformed library file with genes as indices and tfs as columns; membership denoted by True/False.\n",
    "#Checks beforehand if the transformed file has already been created.\n",
    "#Convert each GMT file to a matrix where the indices are genes and columns are genesets. \n",
    "#Cell values are Boolean T/F, showing whether the gene is in\n",
    "#the geneset or not. \n",
    "def library_csv_to_df(library_file):\n",
    "    tformed_lib_fname = library_file.replace('.txt', '_transformed.csv')\n",
    "    if os.path.isfile(tformed_lib_fname):\n",
    "        df = pd.read_csv(tformed_lib_fname, index_col=0, sep='\\t')\n",
    "    else:\n",
    "        print('transforming', library_file)\n",
    "    with open(library_file, 'r') as f:\n",
    "        df = pd.DataFrame(False, index = [''], columns = [''], dtype=bool)\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            row = [x.replace(',1.0', '') for x in row]\n",
    "            #print('transforming', row[0])\n",
    "            s = pd.DataFrame(True, index = row[2:], columns = [row[0]], dtype=bool)\n",
    "            df = pd.concat([df,s], axis=1)\n",
    "    df = df[pd.notnull(df.index)].fillna(False)\n",
    "    df = df.loc[pd.notnull(df.index)]\n",
    "    df.drop('', inplace=True)\n",
    "    df.drop('', axis=1, inplace=True)\n",
    "    df.to_csv(tformed_lib_fname, sep='\\t')\n",
    "    df = df.to_sparse()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Test if creation of geneset matrix works\n",
    "overlap = library_csv_to_df('Combined.gmt')\n",
    "overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_coo_matrix(lib2_df, lib1_tf):\n",
    "\t#input: dataframe of lib2 tf vectors, and the column of lib1 corresponding to a tf\n",
    "\tprint(lib1_tf)\n",
    "\tp_matrix = {}\n",
    "\tfor itf2 in range(0,lib2_df.shape[1]): #if lib1 is the same as lib2, then use 'range(lib1_tf,lib2_df.shape[1])' instead to avoid repeats\n",
    "\t\tintersection = pd.concat([lib2_df.iloc[:,itf2],[lib2_df.iloc[:,itf2]], lib2_df[lib1_tf]], axis=1, join='inner')\n",
    "\t\ta = intersection.shape[0]\n",
    "\t\tb = lib2_df.iloc[:,itf2].sum() - a\n",
    "\t\tc = lib1_tf.sum() - a\n",
    "\t\td = 20000 - a - b - c\n",
    "\t\to, p = stats.fisher_exact([[a,b],[c,d]], alternative='greater')\n",
    "\t\tp_matrix[lib1_tf.name + ',' + lib2_df.columns.values[itf2]] = p\n",
    "\treturn p_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "if __name__ == '__main__': #this mysterious statement here is necessary for parallel processing\n",
    "\tlib1 = 'NetworKIN.gmt' \n",
    "\tlib2 = 'MINT.gmt' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\ttransformed = {}\n",
    "\tfor x in [lib1, lib2]:\n",
    "\t\ttransformed[x] = library_csv_to_df(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRK_Homo sapiens\n",
      "PKCzeta_Homo sapiens\n",
      "MAPK1_Homo sapiens\n",
      "TTK_Homo sapiens\n",
      "CDK2_Homo sapiens\n",
      "CDK1_Homo sapiens\n",
      "PKAalpha_Homo sapiens\n",
      "CK2alpha_Homo sapiens\n",
      "PKBalpha_Homo sapiens\n",
      "PKCdelta_Homo sapiens\n",
      "HIPK2_Homo sapiens\n"
     ]
    },
    {
     "ename": "JoblibTypeError",
     "evalue": "JoblibTypeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7febe7ee3270, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/maayanlab/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/maayanlab/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/maayan.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7febe7ee3270, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/maayanlab/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/maayanlab/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/maayan.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 5\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 5), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 5)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=5)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': r\"#n_jobs is number of simultaneous processes: sev...eplace('.txt', '') + '_coo_p_vals.csv', sep='\\t')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 27, 16, 35, 39, 1772, tzinfo=datetime.timezone.utc), 'msg_id': 'F0D4177C2E324A0AB3228A314863724B', 'msg_type': 'execute_request', 'session': '3034417890BD48F6914CD0EFEA3AB055', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'F0D4177C2E324A0AB3228A314863724B', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'3034417890BD48F6914CD0EFEA3AB055']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': r\"#n_jobs is number of simultaneous processes: sev...eplace('.txt', '') + '_coo_p_vals.csv', sep='\\t')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 27, 16, 35, 39, 1772, tzinfo=datetime.timezone.utc), 'msg_id': 'F0D4177C2E324A0AB3228A314863724B', 'msg_type': 'execute_request', 'session': '3034417890BD48F6914CD0EFEA3AB055', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'F0D4177C2E324A0AB3228A314863724B', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'3034417890BD48F6914CD0EFEA3AB055'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': r\"#n_jobs is number of simultaneous processes: sev...eplace('.txt', '') + '_coo_p_vals.csv', sep='\\t')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 27, 16, 35, 39, 1772, tzinfo=datetime.timezone.utc), 'msg_id': 'F0D4177C2E324A0AB3228A314863724B', 'msg_type': 'execute_request', 'session': '3034417890BD48F6914CD0EFEA3AB055', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'F0D4177C2E324A0AB3228A314863724B', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=r\"#n_jobs is number of simultaneous processes: sev...eplace('.txt', '') + '_coo_p_vals.csv', sep='\\t')\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = r\"#n_jobs is number of simultaneous processes: sev...eplace('.txt', '') + '_coo_p_vals.csv', sep='\\t')\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(r\"#n_jobs is number of simultaneous processes: sev...eplace('.txt', '') + '_coo_p_vals.csv', sep='\\t')\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (r\"#n_jobs is number of simultaneous processes: sev...eplace('.txt', '') + '_coo_p_vals.csv', sep='\\t')\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=r\"#n_jobs is number of simultaneous processes: sev...eplace('.txt', '') + '_coo_p_vals.csv', sep='\\t')\", store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.For object>, <_ast.Expr object>], cell_name='<ipython-input-24-33e35d0e0562>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7febc40247b8, executi..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7febabd03a50, file \"<ipython-input-24-33e35d0e0562>\", line 4>\n        result = <ExecutionResult object at 7febc40247b8, executi..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7febabd03a50, file \"<ipython-input-24-33e35d0e0562>\", line 4>, result=<ExecutionResult object at 7febc40247b8, executi..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7febabd03a50, file \"<ipython-input-24-33e35d0e0562>\", line 4>\n        self.user_global_ns = {'In': ['', 'import csv\\nimport os\\nimport pickle\\nimport numpy ...ats as stats\\nfrom joblib import Parallel, delayed', \"#Input: library file from Enrichr. Output: trans..., sep='\\\\t')\\n    df = df.to_sparse()\\n    return df\", 'def get_coo_matrix(lib2_df, lib1_tf):\\n\\t#input: d...ib2_df.columns.values[itf2]] = p\\n\\treturn p_matrix', \"if __name__ == '__main__': #this mysterious stat...sing\\n\\tlib1 = 'NetworKIN.gmt' \\n\\tlib2 = 'MINT.gmt' \", 'transformed = {}\\nfor x in [lib1, lib2]:\\n\\ttransformed[x] = library_csv_to_df(x)', 'import csv\\nimport os\\nimport pickle\\nimport numpy ...ats as stats\\nfrom joblib import Parallel, delayed', \"#Input: library file from Enrichr. Output: trans..., sep='\\\\t')\\n    df = df.to_sparse()\\n    return df\", 'def get_coo_matrix(lib2_df, lib1_tf):\\n\\t#input: d...ib2_df.columns.values[itf2]] = p\\n\\treturn p_matrix', \"if __name__ == '__main__': #this mysterious stat...sing\\n\\tlib1 = 'NetworKIN.gmt' \\n\\tlib2 = 'MINT.gmt' \", 'transformed = {}\\nfor x in [lib1, lib2]:\\n\\ttransformed[x] = library_csv_to_df(x)', r\"#n_jobs is number of simultaneous processes: sev...eplace('.txt', '') + '_coo_p_vals.csv', sep='\\t')\", 'import csv\\nimport os\\nimport pickle\\nimport numpy ...ats as stats\\nfrom joblib import Parallel, delayed', \"#Input: library file from Enrichr. Output: trans..., sep='\\\\t')\\n    df = df.to_sparse()\\n    return df\", 'def get_coo_matrix(lib2_df, lib1_tf):\\n\\t#input: d...ib2_df.columns.values[itf2]] = p\\n\\treturn p_matrix', r\"#n_jobs is number of simultaneous processes: sev...eplace('.txt', '') + '_coo_p_vals.csv', sep='\\t')\", 'def get_coo_matrix(lib2_df, lib1_tf):\\n\\t#input: d...ib2_df.columns.values[itf2]] = p\\n\\treturn p_matrix', 'import csv\\nimport os\\nimport pickle\\nimport numpy ...ats as stats\\nfrom joblib import Parallel, delayed', \"#Input: library file from Enrichr. Output: trans..., sep='\\\\t')\\n    df = df.to_sparse()\\n    return df\", 'def get_coo_matrix(lib2_df, lib1_tf):\\n\\t#input: d...ib2_df.columns.values[itf2]] = p\\n\\treturn p_matrix', ...], 'Out': {}, 'Parallel': <class 'joblib.parallel.Parallel'>, '_': '', '__': '', '___': '', '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '__doc__': 'Automatically created module for IPython interactive environment', '__loader__': None, ...}\n        self.user_ns = {'In': ['', 'import csv\\nimport os\\nimport pickle\\nimport numpy ...ats as stats\\nfrom joblib import Parallel, delayed', \"#Input: library file from Enrichr. Output: trans..., sep='\\\\t')\\n    df = df.to_sparse()\\n    return df\", 'def get_coo_matrix(lib2_df, lib1_tf):\\n\\t#input: d...ib2_df.columns.values[itf2]] = p\\n\\treturn p_matrix', \"if __name__ == '__main__': #this mysterious stat...sing\\n\\tlib1 = 'NetworKIN.gmt' \\n\\tlib2 = 'MINT.gmt' \", 'transformed = {}\\nfor x in [lib1, lib2]:\\n\\ttransformed[x] = library_csv_to_df(x)', 'import csv\\nimport os\\nimport pickle\\nimport numpy ...ats as stats\\nfrom joblib import Parallel, delayed', \"#Input: library file from Enrichr. Output: trans..., sep='\\\\t')\\n    df = df.to_sparse()\\n    return df\", 'def get_coo_matrix(lib2_df, lib1_tf):\\n\\t#input: d...ib2_df.columns.values[itf2]] = p\\n\\treturn p_matrix', \"if __name__ == '__main__': #this mysterious stat...sing\\n\\tlib1 = 'NetworKIN.gmt' \\n\\tlib2 = 'MINT.gmt' \", 'transformed = {}\\nfor x in [lib1, lib2]:\\n\\ttransformed[x] = library_csv_to_df(x)', r\"#n_jobs is number of simultaneous processes: sev...eplace('.txt', '') + '_coo_p_vals.csv', sep='\\t')\", 'import csv\\nimport os\\nimport pickle\\nimport numpy ...ats as stats\\nfrom joblib import Parallel, delayed', \"#Input: library file from Enrichr. Output: trans..., sep='\\\\t')\\n    df = df.to_sparse()\\n    return df\", 'def get_coo_matrix(lib2_df, lib1_tf):\\n\\t#input: d...ib2_df.columns.values[itf2]] = p\\n\\treturn p_matrix', r\"#n_jobs is number of simultaneous processes: sev...eplace('.txt', '') + '_coo_p_vals.csv', sep='\\t')\", 'def get_coo_matrix(lib2_df, lib1_tf):\\n\\t#input: d...ib2_df.columns.values[itf2]] = p\\n\\treturn p_matrix', 'import csv\\nimport os\\nimport pickle\\nimport numpy ...ats as stats\\nfrom joblib import Parallel, delayed', \"#Input: library file from Enrichr. Output: trans..., sep='\\\\t')\\n    df = df.to_sparse()\\n    return df\", 'def get_coo_matrix(lib2_df, lib1_tf):\\n\\t#input: d...ib2_df.columns.values[itf2]] = p\\n\\treturn p_matrix', ...], 'Out': {}, 'Parallel': <class 'joblib.parallel.Parallel'>, '_': '', '__': '', '___': '', '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '__doc__': 'Automatically created module for IPython interactive environment', '__loader__': None, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/home/maayanlab/Desktop/Projects/KEA3/Combined Dataset/<ipython-input-24-33e35d0e0562> in <module>()\n      1 #n_jobs is number of simultaneous processes: seven is about the highest it can go without slowing computer too much or crashing\n      2 #function iterates over lib2, parallel processing iterates over lib1\n      3 #p_dicts becomes a list of dicts returned by get_coo_matrix for each Parallel iteration\n----> 4 p_dicts = Parallel(n_jobs=7)(delayed(get_coo_matrix)(transformed[lib2], column) for column in transformed[lib1])\n      5 p_combined_dict = { k: v for d in p_dicts for k, v in d.items() }\n      6 p_df = pd.DataFrame(index=tformed_libs[feature_lib].columns, columns = tformed_libs[feature_lib].columns)\n      7 for x in p_combined_dict:\n      8 \ttf1 = x.partition(',')[0]\n      9 \ttf2 = x.partition(',')[2]\n     10 \tp_df.at[tf1,tf2] = p_combined_dict[x]\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/joblib/parallel.py in __call__(self=Parallel(n_jobs=7), iterable=<generator object <genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=7)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nTypeError                                          Tue Jun 27 12:35:39 2017\nPID: 4442                Python 3.6.1: /home/maayanlab/anaconda3/bin/python\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/joblib/parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function get_coo_matrix>, (           PASK_Homo sapiens  CSNK2A1_Homo sapie...alse              False  \n\n[76 rows x 11 columns], 'FRK_Homo sapiens'), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function get_coo_matrix>\n        args = (           PASK_Homo sapiens  CSNK2A1_Homo sapie...alse              False  \n\n[76 rows x 11 columns], 'FRK_Homo sapiens')\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/maayanlab/Desktop/Projects/KEA3/Combined Dataset/<ipython-input-23-433d21291d6d> in get_coo_matrix(lib2_df=           PASK_Homo sapiens  CSNK2A1_Homo sapie...alse              False  \n\n[76 rows x 11 columns], lib1_tf='FRK_Homo sapiens')\n      1 def get_coo_matrix(lib2_df, lib1_tf):\n      2 \t#input: dataframe of lib2 tf vectors, and the column of lib1 corresponding to a tf\n      3 \tprint(lib1_tf)\n      4 \tp_matrix = {}\n      5 \tfor itf2 in range(0,lib2_df.shape[1]): #if lib1 is the same as lib2, then use 'range(lib1_tf,lib2_df.shape[1])' instead to avoid repeats\n----> 6 \t\tintersection = pd.concat([lib2_df.loc[:,itf2][lib2_df.loc[:,itf2]], lib1_tf[lib1_tf]], axis=1, join='inner')\n      7 \t\ta = intersection.shape[0]\n      8 \t\tb = lib2_df.loc[:,itf2].sum() - a\n      9 \t\tc = lib1_tf.sum() - a\n     10 \t\td = 20000 - a - b - c\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self=<pandas.core.indexing._LocIndexer object>, key=(slice(None, None, None), 0))\n   1320             try:\n   1321                 if self._is_scalar_access(key):\n   1322                     return self._getitem_scalar(key)\n   1323             except (KeyError, IndexError):\n   1324                 pass\n-> 1325             return self._getitem_tuple(key)\n        self._getitem_tuple = <bound method _NDFrameIndexer._getitem_tuple of <pandas.core.indexing._LocIndexer object>>\n        key = (slice(None, None, None), 0)\n   1326         else:\n   1327             key = com._apply_if_callable(key, self.obj)\n   1328             return self._getitem_axis(key, axis=0)\n   1329 \n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_tuple(self=<pandas.core.indexing._LocIndexer object>, tup=(slice(None, None, None), 0))\n    831         raise NotImplementedError(\"cannot set using an indexer with a Panel \"\n    832                                   \"yet!\")\n    833 \n    834     def _getitem_tuple(self, tup):\n    835         try:\n--> 836             return self._getitem_lowerdim(tup)\n        self._getitem_lowerdim = <bound method _NDFrameIndexer._getitem_lowerdim of <pandas.core.indexing._LocIndexer object>>\n        tup = (slice(None, None, None), 0)\n    837         except IndexingError:\n    838             pass\n    839 \n    840         # no multi-index, so validate all of the indexers\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_lowerdim(self=<pandas.core.indexing._LocIndexer object>, tup=(slice(None, None, None), 0))\n    962         # to avoid wasted computation\n    963         # df.ix[d1:d2, 0] -> columns first (True)\n    964         # df.ix[0, ['C', 'B', A']] -> rows first (False)\n    965         for i, key in enumerate(tup):\n    966             if is_label_like(key) or isinstance(key, tuple):\n--> 967                 section = self._getitem_axis(key, axis=i)\n        section = undefined\n        self._getitem_axis = <bound method _LocIndexer._getitem_axis of <pandas.core.indexing._LocIndexer object>>\n        key = 0\n        axis = undefined\n        i = 1\n    968 \n    969                 # we have yielded a scalar ?\n    970                 if not is_list_like_indexer(section):\n    971                     return section\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self=<pandas.core.indexing._LocIndexer object>, key=0, axis=1)\n   1546                 indexer = [slice(None)] * self.ndim\n   1547                 indexer[axis] = locs\n   1548                 return self.obj.iloc[tuple(indexer)]\n   1549 \n   1550         # fall thru to straight lookup\n-> 1551         self._has_valid_type(key, axis)\n        self._has_valid_type = <bound method _LocIndexer._has_valid_type of <pandas.core.indexing._LocIndexer object>>\n        key = 0\n        axis = 1\n   1552         return self._get_label(key, axis=axis)\n   1553 \n   1554 \n   1555 class _iLocIndexer(_LocationIndexer):\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _has_valid_type(self=<pandas.core.indexing._LocIndexer object>, key=0, axis=1)\n   1427                                     \"key\")\n   1428                 raise KeyError(\"the label [%s] is not in the [%s]\" %\n   1429                                (key, self.obj._get_axis_name(axis)))\n   1430 \n   1431             try:\n-> 1432                 key = self._convert_scalar_indexer(key, axis)\n        key = 0\n        self._convert_scalar_indexer = <bound method _NDFrameIndexer._convert_scalar_indexer of <pandas.core.indexing._LocIndexer object>>\n        axis = 1\n   1433                 if not ax.contains(key):\n   1434                     error()\n   1435             except TypeError as e:\n   1436 \n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _convert_scalar_indexer(self=<pandas.core.indexing._LocIndexer object>, key=0, axis=1)\n    231 \n    232     def _convert_scalar_indexer(self, key, axis):\n    233         # if we are accessing via lowered dim, use the last dim\n    234         ax = self.obj._get_axis(min(axis, self.ndim - 1))\n    235         # a scalar\n--> 236         return ax._convert_scalar_indexer(key, kind=self.name)\n        ax._convert_scalar_indexer = <bound method Index._convert_scalar_indexer of I...ns', 'AKT1_Homo sapiens'],\n      dtype='object')>\n        key = 0\n        self.name = 'loc'\n    237 \n    238     def _convert_slice_indexer(self, key, axis):\n    239         # if we are accessing via lowered dim, use the last dim\n    240         ax = self.obj._get_axis(min(axis, self.ndim - 1))\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py in _convert_scalar_indexer(self=Index(['PASK_Homo sapiens', 'CSNK2A1_Homo sapien...ens', 'AKT1_Homo sapiens'],\n      dtype='object'), key=0, kind='loc')\n   1280                                               'mixed']:\n   1281                     return self._invalid_indexer('label', key)\n   1282 \n   1283             elif kind in ['loc'] and is_integer(key):\n   1284                 if not self.holds_integer():\n-> 1285                     return self._invalid_indexer('label', key)\n        self._invalid_indexer = <bound method Index._invalid_indexer of Index(['...ns', 'AKT1_Homo sapiens'],\n      dtype='object')>\n        key = 0\n   1286 \n   1287         return key\n   1288 \n   1289     _index_shared_docs['_convert_slice_indexer'] = \"\"\"\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py in _invalid_indexer(self=Index(['PASK_Homo sapiens', 'CSNK2A1_Homo sapien...ens', 'AKT1_Homo sapiens'],\n      dtype='object'), form='label', key=0)\n   1464     def _invalid_indexer(self, form, key):\n   1465         \"\"\" consistent invalid indexer message \"\"\"\n   1466         raise TypeError(\"cannot do {form} indexing on {klass} with these \"\n   1467                         \"indexers [{key}] of {kind}\".format(\n   1468                             form=form, klass=type(self), key=key,\n-> 1469                             kind=type(key)))\n        key = 0\n   1470 \n   1471     def get_duplicates(self):\n   1472         from collections import defaultdict\n   1473         counter = defaultdict(lambda: 0)\n\nTypeError: cannot do label indexing on <class 'pandas.core.indexes.base.Index'> with these indexers [0] of <class 'int'>\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/maayanlab/anaconda3/lib/python3.6/site-packages/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/maayanlab/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/maayanlab/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"<ipython-input-23-433d21291d6d>\", line 6, in get_coo_matrix\n    intersection = pd.concat([lib2_df.loc[:,itf2][lib2_df.loc[:,itf2]], lib1_tf[lib1_tf]], axis=1, join='inner')\n  File \"/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1325, in __getitem__\n    return self._getitem_tuple(key)\n  File \"/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\", line 836, in _getitem_tuple\n    return self._getitem_lowerdim(tup)\n  File \"/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\", line 967, in _getitem_lowerdim\n    section = self._getitem_axis(key, axis=i)\n  File \"/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1551, in _getitem_axis\n    self._has_valid_type(key, axis)\n  File \"/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1432, in _has_valid_type\n    key = self._convert_scalar_indexer(key, axis)\n  File \"/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\", line 236, in _convert_scalar_indexer\n    return ax._convert_scalar_indexer(key, kind=self.name)\n  File \"/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 1285, in _convert_scalar_indexer\n    return self._invalid_indexer('label', key)\n  File \"/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 1469, in _invalid_indexer\n    kind=type(key)))\nTypeError: cannot do label indexing on <class 'pandas.core.indexes.base.Index'> with these indexers [0] of <class 'int'>\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/maayanlab/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/maayanlab/anaconda3/lib/python3.6/site-packages/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\njoblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nTypeError                                          Tue Jun 27 12:35:39 2017\nPID: 4442                Python 3.6.1: /home/maayanlab/anaconda3/bin/python\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/joblib/parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function get_coo_matrix>, (           PASK_Homo sapiens  CSNK2A1_Homo sapie...alse              False  \n\n[76 rows x 11 columns], 'FRK_Homo sapiens'), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function get_coo_matrix>\n        args = (           PASK_Homo sapiens  CSNK2A1_Homo sapie...alse              False  \n\n[76 rows x 11 columns], 'FRK_Homo sapiens')\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/maayanlab/Desktop/Projects/KEA3/Combined Dataset/<ipython-input-23-433d21291d6d> in get_coo_matrix(lib2_df=           PASK_Homo sapiens  CSNK2A1_Homo sapie...alse              False  \n\n[76 rows x 11 columns], lib1_tf='FRK_Homo sapiens')\n      1 def get_coo_matrix(lib2_df, lib1_tf):\n      2 \t#input: dataframe of lib2 tf vectors, and the column of lib1 corresponding to a tf\n      3 \tprint(lib1_tf)\n      4 \tp_matrix = {}\n      5 \tfor itf2 in range(0,lib2_df.shape[1]): #if lib1 is the same as lib2, then use 'range(lib1_tf,lib2_df.shape[1])' instead to avoid repeats\n----> 6 \t\tintersection = pd.concat([lib2_df.loc[:,itf2][lib2_df.loc[:,itf2]], lib1_tf[lib1_tf]], axis=1, join='inner')\n      7 \t\ta = intersection.shape[0]\n      8 \t\tb = lib2_df.loc[:,itf2].sum() - a\n      9 \t\tc = lib1_tf.sum() - a\n     10 \t\td = 20000 - a - b - c\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self=<pandas.core.indexing._LocIndexer object>, key=(slice(None, None, None), 0))\n   1320             try:\n   1321                 if self._is_scalar_access(key):\n   1322                     return self._getitem_scalar(key)\n   1323             except (KeyError, IndexError):\n   1324                 pass\n-> 1325             return self._getitem_tuple(key)\n        self._getitem_tuple = <bound method _NDFrameIndexer._getitem_tuple of <pandas.core.indexing._LocIndexer object>>\n        key = (slice(None, None, None), 0)\n   1326         else:\n   1327             key = com._apply_if_callable(key, self.obj)\n   1328             return self._getitem_axis(key, axis=0)\n   1329 \n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_tuple(self=<pandas.core.indexing._LocIndexer object>, tup=(slice(None, None, None), 0))\n    831         raise NotImplementedError(\"cannot set using an indexer with a Panel \"\n    832                                   \"yet!\")\n    833 \n    834     def _getitem_tuple(self, tup):\n    835         try:\n--> 836             return self._getitem_lowerdim(tup)\n        self._getitem_lowerdim = <bound method _NDFrameIndexer._getitem_lowerdim of <pandas.core.indexing._LocIndexer object>>\n        tup = (slice(None, None, None), 0)\n    837         except IndexingError:\n    838             pass\n    839 \n    840         # no multi-index, so validate all of the indexers\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_lowerdim(self=<pandas.core.indexing._LocIndexer object>, tup=(slice(None, None, None), 0))\n    962         # to avoid wasted computation\n    963         # df.ix[d1:d2, 0] -> columns first (True)\n    964         # df.ix[0, ['C', 'B', A']] -> rows first (False)\n    965         for i, key in enumerate(tup):\n    966             if is_label_like(key) or isinstance(key, tuple):\n--> 967                 section = self._getitem_axis(key, axis=i)\n        section = undefined\n        self._getitem_axis = <bound method _LocIndexer._getitem_axis of <pandas.core.indexing._LocIndexer object>>\n        key = 0\n        axis = undefined\n        i = 1\n    968 \n    969                 # we have yielded a scalar ?\n    970                 if not is_list_like_indexer(section):\n    971                     return section\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self=<pandas.core.indexing._LocIndexer object>, key=0, axis=1)\n   1546                 indexer = [slice(None)] * self.ndim\n   1547                 indexer[axis] = locs\n   1548                 return self.obj.iloc[tuple(indexer)]\n   1549 \n   1550         # fall thru to straight lookup\n-> 1551         self._has_valid_type(key, axis)\n        self._has_valid_type = <bound method _LocIndexer._has_valid_type of <pandas.core.indexing._LocIndexer object>>\n        key = 0\n        axis = 1\n   1552         return self._get_label(key, axis=axis)\n   1553 \n   1554 \n   1555 class _iLocIndexer(_LocationIndexer):\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _has_valid_type(self=<pandas.core.indexing._LocIndexer object>, key=0, axis=1)\n   1427                                     \"key\")\n   1428                 raise KeyError(\"the label [%s] is not in the [%s]\" %\n   1429                                (key, self.obj._get_axis_name(axis)))\n   1430 \n   1431             try:\n-> 1432                 key = self._convert_scalar_indexer(key, axis)\n        key = 0\n        self._convert_scalar_indexer = <bound method _NDFrameIndexer._convert_scalar_indexer of <pandas.core.indexing._LocIndexer object>>\n        axis = 1\n   1433                 if not ax.contains(key):\n   1434                     error()\n   1435             except TypeError as e:\n   1436 \n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _convert_scalar_indexer(self=<pandas.core.indexing._LocIndexer object>, key=0, axis=1)\n    231 \n    232     def _convert_scalar_indexer(self, key, axis):\n    233         # if we are accessing via lowered dim, use the last dim\n    234         ax = self.obj._get_axis(min(axis, self.ndim - 1))\n    235         # a scalar\n--> 236         return ax._convert_scalar_indexer(key, kind=self.name)\n        ax._convert_scalar_indexer = <bound method Index._convert_scalar_indexer of I...ns', 'AKT1_Homo sapiens'],\n      dtype='object')>\n        key = 0\n        self.name = 'loc'\n    237 \n    238     def _convert_slice_indexer(self, key, axis):\n    239         # if we are accessing via lowered dim, use the last dim\n    240         ax = self.obj._get_axis(min(axis, self.ndim - 1))\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py in _convert_scalar_indexer(self=Index(['PASK_Homo sapiens', 'CSNK2A1_Homo sapien...ens', 'AKT1_Homo sapiens'],\n      dtype='object'), key=0, kind='loc')\n   1280                                               'mixed']:\n   1281                     return self._invalid_indexer('label', key)\n   1282 \n   1283             elif kind in ['loc'] and is_integer(key):\n   1284                 if not self.holds_integer():\n-> 1285                     return self._invalid_indexer('label', key)\n        self._invalid_indexer = <bound method Index._invalid_indexer of Index(['...ns', 'AKT1_Homo sapiens'],\n      dtype='object')>\n        key = 0\n   1286 \n   1287         return key\n   1288 \n   1289     _index_shared_docs['_convert_slice_indexer'] = \"\"\"\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py in _invalid_indexer(self=Index(['PASK_Homo sapiens', 'CSNK2A1_Homo sapien...ens', 'AKT1_Homo sapiens'],\n      dtype='object'), form='label', key=0)\n   1464     def _invalid_indexer(self, form, key):\n   1465         \"\"\" consistent invalid indexer message \"\"\"\n   1466         raise TypeError(\"cannot do {form} indexing on {klass} with these \"\n   1467                         \"indexers [{key}] of {kind}\".format(\n   1468                             form=form, klass=type(self), key=key,\n-> 1469                             kind=type(key)))\n        key = 0\n   1470 \n   1471     def get_duplicates(self):\n   1472         from collections import defaultdict\n   1473         counter = defaultdict(lambda: 0)\n\nTypeError: cannot do label indexing on <class 'pandas.core.indexes.base.Index'> with these indexers [0] of <class 'int'>\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/home/maayanlab/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/maayanlab/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nTypeError                                          Tue Jun 27 12:35:39 2017\nPID: 4442                Python 3.6.1: /home/maayanlab/anaconda3/bin/python\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/joblib/parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function get_coo_matrix>, (           PASK_Homo sapiens  CSNK2A1_Homo sapie...alse              False  \n\n[76 rows x 11 columns], 'FRK_Homo sapiens'), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function get_coo_matrix>\n        args = (           PASK_Homo sapiens  CSNK2A1_Homo sapie...alse              False  \n\n[76 rows x 11 columns], 'FRK_Homo sapiens')\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/maayanlab/Desktop/Projects/KEA3/Combined Dataset/<ipython-input-23-433d21291d6d> in get_coo_matrix(lib2_df=           PASK_Homo sapiens  CSNK2A1_Homo sapie...alse              False  \n\n[76 rows x 11 columns], lib1_tf='FRK_Homo sapiens')\n      1 def get_coo_matrix(lib2_df, lib1_tf):\n      2 \t#input: dataframe of lib2 tf vectors, and the column of lib1 corresponding to a tf\n      3 \tprint(lib1_tf)\n      4 \tp_matrix = {}\n      5 \tfor itf2 in range(0,lib2_df.shape[1]): #if lib1 is the same as lib2, then use 'range(lib1_tf,lib2_df.shape[1])' instead to avoid repeats\n----> 6 \t\tintersection = pd.concat([lib2_df.loc[:,itf2][lib2_df.loc[:,itf2]], lib1_tf[lib1_tf]], axis=1, join='inner')\n      7 \t\ta = intersection.shape[0]\n      8 \t\tb = lib2_df.loc[:,itf2].sum() - a\n      9 \t\tc = lib1_tf.sum() - a\n     10 \t\td = 20000 - a - b - c\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self=<pandas.core.indexing._LocIndexer object>, key=(slice(None, None, None), 0))\n   1320             try:\n   1321                 if self._is_scalar_access(key):\n   1322                     return self._getitem_scalar(key)\n   1323             except (KeyError, IndexError):\n   1324                 pass\n-> 1325             return self._getitem_tuple(key)\n        self._getitem_tuple = <bound method _NDFrameIndexer._getitem_tuple of <pandas.core.indexing._LocIndexer object>>\n        key = (slice(None, None, None), 0)\n   1326         else:\n   1327             key = com._apply_if_callable(key, self.obj)\n   1328             return self._getitem_axis(key, axis=0)\n   1329 \n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_tuple(self=<pandas.core.indexing._LocIndexer object>, tup=(slice(None, None, None), 0))\n    831         raise NotImplementedError(\"cannot set using an indexer with a Panel \"\n    832                                   \"yet!\")\n    833 \n    834     def _getitem_tuple(self, tup):\n    835         try:\n--> 836             return self._getitem_lowerdim(tup)\n        self._getitem_lowerdim = <bound method _NDFrameIndexer._getitem_lowerdim of <pandas.core.indexing._LocIndexer object>>\n        tup = (slice(None, None, None), 0)\n    837         except IndexingError:\n    838             pass\n    839 \n    840         # no multi-index, so validate all of the indexers\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_lowerdim(self=<pandas.core.indexing._LocIndexer object>, tup=(slice(None, None, None), 0))\n    962         # to avoid wasted computation\n    963         # df.ix[d1:d2, 0] -> columns first (True)\n    964         # df.ix[0, ['C', 'B', A']] -> rows first (False)\n    965         for i, key in enumerate(tup):\n    966             if is_label_like(key) or isinstance(key, tuple):\n--> 967                 section = self._getitem_axis(key, axis=i)\n        section = undefined\n        self._getitem_axis = <bound method _LocIndexer._getitem_axis of <pandas.core.indexing._LocIndexer object>>\n        key = 0\n        axis = undefined\n        i = 1\n    968 \n    969                 # we have yielded a scalar ?\n    970                 if not is_list_like_indexer(section):\n    971                     return section\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self=<pandas.core.indexing._LocIndexer object>, key=0, axis=1)\n   1546                 indexer = [slice(None)] * self.ndim\n   1547                 indexer[axis] = locs\n   1548                 return self.obj.iloc[tuple(indexer)]\n   1549 \n   1550         # fall thru to straight lookup\n-> 1551         self._has_valid_type(key, axis)\n        self._has_valid_type = <bound method _LocIndexer._has_valid_type of <pandas.core.indexing._LocIndexer object>>\n        key = 0\n        axis = 1\n   1552         return self._get_label(key, axis=axis)\n   1553 \n   1554 \n   1555 class _iLocIndexer(_LocationIndexer):\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _has_valid_type(self=<pandas.core.indexing._LocIndexer object>, key=0, axis=1)\n   1427                                     \"key\")\n   1428                 raise KeyError(\"the label [%s] is not in the [%s]\" %\n   1429                                (key, self.obj._get_axis_name(axis)))\n   1430 \n   1431             try:\n-> 1432                 key = self._convert_scalar_indexer(key, axis)\n        key = 0\n        self._convert_scalar_indexer = <bound method _NDFrameIndexer._convert_scalar_indexer of <pandas.core.indexing._LocIndexer object>>\n        axis = 1\n   1433                 if not ax.contains(key):\n   1434                     error()\n   1435             except TypeError as e:\n   1436 \n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _convert_scalar_indexer(self=<pandas.core.indexing._LocIndexer object>, key=0, axis=1)\n    231 \n    232     def _convert_scalar_indexer(self, key, axis):\n    233         # if we are accessing via lowered dim, use the last dim\n    234         ax = self.obj._get_axis(min(axis, self.ndim - 1))\n    235         # a scalar\n--> 236         return ax._convert_scalar_indexer(key, kind=self.name)\n        ax._convert_scalar_indexer = <bound method Index._convert_scalar_indexer of I...ns', 'AKT1_Homo sapiens'],\n      dtype='object')>\n        key = 0\n        self.name = 'loc'\n    237 \n    238     def _convert_slice_indexer(self, key, axis):\n    239         # if we are accessing via lowered dim, use the last dim\n    240         ax = self.obj._get_axis(min(axis, self.ndim - 1))\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py in _convert_scalar_indexer(self=Index(['PASK_Homo sapiens', 'CSNK2A1_Homo sapien...ens', 'AKT1_Homo sapiens'],\n      dtype='object'), key=0, kind='loc')\n   1280                                               'mixed']:\n   1281                     return self._invalid_indexer('label', key)\n   1282 \n   1283             elif kind in ['loc'] and is_integer(key):\n   1284                 if not self.holds_integer():\n-> 1285                     return self._invalid_indexer('label', key)\n        self._invalid_indexer = <bound method Index._invalid_indexer of Index(['...ns', 'AKT1_Homo sapiens'],\n      dtype='object')>\n        key = 0\n   1286 \n   1287         return key\n   1288 \n   1289     _index_shared_docs['_convert_slice_indexer'] = \"\"\"\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py in _invalid_indexer(self=Index(['PASK_Homo sapiens', 'CSNK2A1_Homo sapien...ens', 'AKT1_Homo sapiens'],\n      dtype='object'), form='label', key=0)\n   1464     def _invalid_indexer(self, form, key):\n   1465         \"\"\" consistent invalid indexer message \"\"\"\n   1466         raise TypeError(\"cannot do {form} indexing on {klass} with these \"\n   1467                         \"indexers [{key}] of {kind}\".format(\n   1468                             form=form, klass=type(self), key=key,\n-> 1469                             kind=type(key)))\n        key = 0\n   1470 \n   1471     def get_duplicates(self):\n   1472         from collections import defaultdict\n   1473         counter = defaultdict(lambda: 0)\n\nTypeError: cannot do label indexing on <class 'pandas.core.indexes.base.Index'> with these indexers [0] of <class 'int'>\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibTypeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-33e35d0e0562>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#function iterates over lib2, parallel processing iterates over lib1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#p_dicts becomes a list of dicts returned by get_coo_matrix for each Parallel iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mp_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_coo_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlib2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransformed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlib1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mp_combined_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp_dicts\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtformed_libs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_lib\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtformed_libs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_lib\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/maayanlab/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/maayanlab/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibTypeError\u001b[0m: JoblibTypeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7febe7ee3270, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/maayanlab/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/maayanlab/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/maayan.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7febe7ee3270, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/maayanlab/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/maayanlab/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/maayan.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 5\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 5), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 5)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=5)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': r\"#n_jobs is number of simultaneous processes: sev...eplace('.txt', '') + '_coo_p_vals.csv', sep='\\t')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 27, 16, 35, 39, 1772, tzinfo=datetime.timezone.utc), 'msg_id': 'F0D4177C2E324A0AB3228A314863724B', 'msg_type': 'execute_request', 'session': '3034417890BD48F6914CD0EFEA3AB055', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'F0D4177C2E324A0AB3228A314863724B', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'3034417890BD48F6914CD0EFEA3AB055']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': r\"#n_jobs is number of simultaneous processes: sev...eplace('.txt', '') + '_coo_p_vals.csv', sep='\\t')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 27, 16, 35, 39, 1772, tzinfo=datetime.timezone.utc), 'msg_id': 'F0D4177C2E324A0AB3228A314863724B', 'msg_type': 'execute_request', 'session': '3034417890BD48F6914CD0EFEA3AB055', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'F0D4177C2E324A0AB3228A314863724B', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'3034417890BD48F6914CD0EFEA3AB055'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': r\"#n_jobs is number of simultaneous processes: sev...eplace('.txt', '') + '_coo_p_vals.csv', sep='\\t')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 6, 27, 16, 35, 39, 1772, tzinfo=datetime.timezone.utc), 'msg_id': 'F0D4177C2E324A0AB3228A314863724B', 'msg_type': 'execute_request', 'session': '3034417890BD48F6914CD0EFEA3AB055', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'F0D4177C2E324A0AB3228A314863724B', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=r\"#n_jobs is number of simultaneous processes: sev...eplace('.txt', '') + '_coo_p_vals.csv', sep='\\t')\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = r\"#n_jobs is number of simultaneous processes: sev...eplace('.txt', '') + '_coo_p_vals.csv', sep='\\t')\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(r\"#n_jobs is number of simultaneous processes: sev...eplace('.txt', '') + '_coo_p_vals.csv', sep='\\t')\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (r\"#n_jobs is number of simultaneous processes: sev...eplace('.txt', '') + '_coo_p_vals.csv', sep='\\t')\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=r\"#n_jobs is number of simultaneous processes: sev...eplace('.txt', '') + '_coo_p_vals.csv', sep='\\t')\", store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.For object>, <_ast.Expr object>], cell_name='<ipython-input-24-33e35d0e0562>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7febc40247b8, executi..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7febabd03a50, file \"<ipython-input-24-33e35d0e0562>\", line 4>\n        result = <ExecutionResult object at 7febc40247b8, executi..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7febabd03a50, file \"<ipython-input-24-33e35d0e0562>\", line 4>, result=<ExecutionResult object at 7febc40247b8, executi..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7febabd03a50, file \"<ipython-input-24-33e35d0e0562>\", line 4>\n        self.user_global_ns = {'In': ['', 'import csv\\nimport os\\nimport pickle\\nimport numpy ...ats as stats\\nfrom joblib import Parallel, delayed', \"#Input: library file from Enrichr. Output: trans..., sep='\\\\t')\\n    df = df.to_sparse()\\n    return df\", 'def get_coo_matrix(lib2_df, lib1_tf):\\n\\t#input: d...ib2_df.columns.values[itf2]] = p\\n\\treturn p_matrix', \"if __name__ == '__main__': #this mysterious stat...sing\\n\\tlib1 = 'NetworKIN.gmt' \\n\\tlib2 = 'MINT.gmt' \", 'transformed = {}\\nfor x in [lib1, lib2]:\\n\\ttransformed[x] = library_csv_to_df(x)', 'import csv\\nimport os\\nimport pickle\\nimport numpy ...ats as stats\\nfrom joblib import Parallel, delayed', \"#Input: library file from Enrichr. Output: trans..., sep='\\\\t')\\n    df = df.to_sparse()\\n    return df\", 'def get_coo_matrix(lib2_df, lib1_tf):\\n\\t#input: d...ib2_df.columns.values[itf2]] = p\\n\\treturn p_matrix', \"if __name__ == '__main__': #this mysterious stat...sing\\n\\tlib1 = 'NetworKIN.gmt' \\n\\tlib2 = 'MINT.gmt' \", 'transformed = {}\\nfor x in [lib1, lib2]:\\n\\ttransformed[x] = library_csv_to_df(x)', r\"#n_jobs is number of simultaneous processes: sev...eplace('.txt', '') + '_coo_p_vals.csv', sep='\\t')\", 'import csv\\nimport os\\nimport pickle\\nimport numpy ...ats as stats\\nfrom joblib import Parallel, delayed', \"#Input: library file from Enrichr. Output: trans..., sep='\\\\t')\\n    df = df.to_sparse()\\n    return df\", 'def get_coo_matrix(lib2_df, lib1_tf):\\n\\t#input: d...ib2_df.columns.values[itf2]] = p\\n\\treturn p_matrix', r\"#n_jobs is number of simultaneous processes: sev...eplace('.txt', '') + '_coo_p_vals.csv', sep='\\t')\", 'def get_coo_matrix(lib2_df, lib1_tf):\\n\\t#input: d...ib2_df.columns.values[itf2]] = p\\n\\treturn p_matrix', 'import csv\\nimport os\\nimport pickle\\nimport numpy ...ats as stats\\nfrom joblib import Parallel, delayed', \"#Input: library file from Enrichr. Output: trans..., sep='\\\\t')\\n    df = df.to_sparse()\\n    return df\", 'def get_coo_matrix(lib2_df, lib1_tf):\\n\\t#input: d...ib2_df.columns.values[itf2]] = p\\n\\treturn p_matrix', ...], 'Out': {}, 'Parallel': <class 'joblib.parallel.Parallel'>, '_': '', '__': '', '___': '', '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '__doc__': 'Automatically created module for IPython interactive environment', '__loader__': None, ...}\n        self.user_ns = {'In': ['', 'import csv\\nimport os\\nimport pickle\\nimport numpy ...ats as stats\\nfrom joblib import Parallel, delayed', \"#Input: library file from Enrichr. Output: trans..., sep='\\\\t')\\n    df = df.to_sparse()\\n    return df\", 'def get_coo_matrix(lib2_df, lib1_tf):\\n\\t#input: d...ib2_df.columns.values[itf2]] = p\\n\\treturn p_matrix', \"if __name__ == '__main__': #this mysterious stat...sing\\n\\tlib1 = 'NetworKIN.gmt' \\n\\tlib2 = 'MINT.gmt' \", 'transformed = {}\\nfor x in [lib1, lib2]:\\n\\ttransformed[x] = library_csv_to_df(x)', 'import csv\\nimport os\\nimport pickle\\nimport numpy ...ats as stats\\nfrom joblib import Parallel, delayed', \"#Input: library file from Enrichr. Output: trans..., sep='\\\\t')\\n    df = df.to_sparse()\\n    return df\", 'def get_coo_matrix(lib2_df, lib1_tf):\\n\\t#input: d...ib2_df.columns.values[itf2]] = p\\n\\treturn p_matrix', \"if __name__ == '__main__': #this mysterious stat...sing\\n\\tlib1 = 'NetworKIN.gmt' \\n\\tlib2 = 'MINT.gmt' \", 'transformed = {}\\nfor x in [lib1, lib2]:\\n\\ttransformed[x] = library_csv_to_df(x)', r\"#n_jobs is number of simultaneous processes: sev...eplace('.txt', '') + '_coo_p_vals.csv', sep='\\t')\", 'import csv\\nimport os\\nimport pickle\\nimport numpy ...ats as stats\\nfrom joblib import Parallel, delayed', \"#Input: library file from Enrichr. Output: trans..., sep='\\\\t')\\n    df = df.to_sparse()\\n    return df\", 'def get_coo_matrix(lib2_df, lib1_tf):\\n\\t#input: d...ib2_df.columns.values[itf2]] = p\\n\\treturn p_matrix', r\"#n_jobs is number of simultaneous processes: sev...eplace('.txt', '') + '_coo_p_vals.csv', sep='\\t')\", 'def get_coo_matrix(lib2_df, lib1_tf):\\n\\t#input: d...ib2_df.columns.values[itf2]] = p\\n\\treturn p_matrix', 'import csv\\nimport os\\nimport pickle\\nimport numpy ...ats as stats\\nfrom joblib import Parallel, delayed', \"#Input: library file from Enrichr. Output: trans..., sep='\\\\t')\\n    df = df.to_sparse()\\n    return df\", 'def get_coo_matrix(lib2_df, lib1_tf):\\n\\t#input: d...ib2_df.columns.values[itf2]] = p\\n\\treturn p_matrix', ...], 'Out': {}, 'Parallel': <class 'joblib.parallel.Parallel'>, '_': '', '__': '', '___': '', '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '__doc__': 'Automatically created module for IPython interactive environment', '__loader__': None, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/home/maayanlab/Desktop/Projects/KEA3/Combined Dataset/<ipython-input-24-33e35d0e0562> in <module>()\n      1 #n_jobs is number of simultaneous processes: seven is about the highest it can go without slowing computer too much or crashing\n      2 #function iterates over lib2, parallel processing iterates over lib1\n      3 #p_dicts becomes a list of dicts returned by get_coo_matrix for each Parallel iteration\n----> 4 p_dicts = Parallel(n_jobs=7)(delayed(get_coo_matrix)(transformed[lib2], column) for column in transformed[lib1])\n      5 p_combined_dict = { k: v for d in p_dicts for k, v in d.items() }\n      6 p_df = pd.DataFrame(index=tformed_libs[feature_lib].columns, columns = tformed_libs[feature_lib].columns)\n      7 for x in p_combined_dict:\n      8 \ttf1 = x.partition(',')[0]\n      9 \ttf2 = x.partition(',')[2]\n     10 \tp_df.at[tf1,tf2] = p_combined_dict[x]\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/joblib/parallel.py in __call__(self=Parallel(n_jobs=7), iterable=<generator object <genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=7)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nTypeError                                          Tue Jun 27 12:35:39 2017\nPID: 4442                Python 3.6.1: /home/maayanlab/anaconda3/bin/python\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/joblib/parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function get_coo_matrix>, (           PASK_Homo sapiens  CSNK2A1_Homo sapie...alse              False  \n\n[76 rows x 11 columns], 'FRK_Homo sapiens'), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function get_coo_matrix>\n        args = (           PASK_Homo sapiens  CSNK2A1_Homo sapie...alse              False  \n\n[76 rows x 11 columns], 'FRK_Homo sapiens')\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/maayanlab/Desktop/Projects/KEA3/Combined Dataset/<ipython-input-23-433d21291d6d> in get_coo_matrix(lib2_df=           PASK_Homo sapiens  CSNK2A1_Homo sapie...alse              False  \n\n[76 rows x 11 columns], lib1_tf='FRK_Homo sapiens')\n      1 def get_coo_matrix(lib2_df, lib1_tf):\n      2 \t#input: dataframe of lib2 tf vectors, and the column of lib1 corresponding to a tf\n      3 \tprint(lib1_tf)\n      4 \tp_matrix = {}\n      5 \tfor itf2 in range(0,lib2_df.shape[1]): #if lib1 is the same as lib2, then use 'range(lib1_tf,lib2_df.shape[1])' instead to avoid repeats\n----> 6 \t\tintersection = pd.concat([lib2_df.loc[:,itf2][lib2_df.loc[:,itf2]], lib1_tf[lib1_tf]], axis=1, join='inner')\n      7 \t\ta = intersection.shape[0]\n      8 \t\tb = lib2_df.loc[:,itf2].sum() - a\n      9 \t\tc = lib1_tf.sum() - a\n     10 \t\td = 20000 - a - b - c\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self=<pandas.core.indexing._LocIndexer object>, key=(slice(None, None, None), 0))\n   1320             try:\n   1321                 if self._is_scalar_access(key):\n   1322                     return self._getitem_scalar(key)\n   1323             except (KeyError, IndexError):\n   1324                 pass\n-> 1325             return self._getitem_tuple(key)\n        self._getitem_tuple = <bound method _NDFrameIndexer._getitem_tuple of <pandas.core.indexing._LocIndexer object>>\n        key = (slice(None, None, None), 0)\n   1326         else:\n   1327             key = com._apply_if_callable(key, self.obj)\n   1328             return self._getitem_axis(key, axis=0)\n   1329 \n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_tuple(self=<pandas.core.indexing._LocIndexer object>, tup=(slice(None, None, None), 0))\n    831         raise NotImplementedError(\"cannot set using an indexer with a Panel \"\n    832                                   \"yet!\")\n    833 \n    834     def _getitem_tuple(self, tup):\n    835         try:\n--> 836             return self._getitem_lowerdim(tup)\n        self._getitem_lowerdim = <bound method _NDFrameIndexer._getitem_lowerdim of <pandas.core.indexing._LocIndexer object>>\n        tup = (slice(None, None, None), 0)\n    837         except IndexingError:\n    838             pass\n    839 \n    840         # no multi-index, so validate all of the indexers\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_lowerdim(self=<pandas.core.indexing._LocIndexer object>, tup=(slice(None, None, None), 0))\n    962         # to avoid wasted computation\n    963         # df.ix[d1:d2, 0] -> columns first (True)\n    964         # df.ix[0, ['C', 'B', A']] -> rows first (False)\n    965         for i, key in enumerate(tup):\n    966             if is_label_like(key) or isinstance(key, tuple):\n--> 967                 section = self._getitem_axis(key, axis=i)\n        section = undefined\n        self._getitem_axis = <bound method _LocIndexer._getitem_axis of <pandas.core.indexing._LocIndexer object>>\n        key = 0\n        axis = undefined\n        i = 1\n    968 \n    969                 # we have yielded a scalar ?\n    970                 if not is_list_like_indexer(section):\n    971                     return section\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self=<pandas.core.indexing._LocIndexer object>, key=0, axis=1)\n   1546                 indexer = [slice(None)] * self.ndim\n   1547                 indexer[axis] = locs\n   1548                 return self.obj.iloc[tuple(indexer)]\n   1549 \n   1550         # fall thru to straight lookup\n-> 1551         self._has_valid_type(key, axis)\n        self._has_valid_type = <bound method _LocIndexer._has_valid_type of <pandas.core.indexing._LocIndexer object>>\n        key = 0\n        axis = 1\n   1552         return self._get_label(key, axis=axis)\n   1553 \n   1554 \n   1555 class _iLocIndexer(_LocationIndexer):\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _has_valid_type(self=<pandas.core.indexing._LocIndexer object>, key=0, axis=1)\n   1427                                     \"key\")\n   1428                 raise KeyError(\"the label [%s] is not in the [%s]\" %\n   1429                                (key, self.obj._get_axis_name(axis)))\n   1430 \n   1431             try:\n-> 1432                 key = self._convert_scalar_indexer(key, axis)\n        key = 0\n        self._convert_scalar_indexer = <bound method _NDFrameIndexer._convert_scalar_indexer of <pandas.core.indexing._LocIndexer object>>\n        axis = 1\n   1433                 if not ax.contains(key):\n   1434                     error()\n   1435             except TypeError as e:\n   1436 \n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _convert_scalar_indexer(self=<pandas.core.indexing._LocIndexer object>, key=0, axis=1)\n    231 \n    232     def _convert_scalar_indexer(self, key, axis):\n    233         # if we are accessing via lowered dim, use the last dim\n    234         ax = self.obj._get_axis(min(axis, self.ndim - 1))\n    235         # a scalar\n--> 236         return ax._convert_scalar_indexer(key, kind=self.name)\n        ax._convert_scalar_indexer = <bound method Index._convert_scalar_indexer of I...ns', 'AKT1_Homo sapiens'],\n      dtype='object')>\n        key = 0\n        self.name = 'loc'\n    237 \n    238     def _convert_slice_indexer(self, key, axis):\n    239         # if we are accessing via lowered dim, use the last dim\n    240         ax = self.obj._get_axis(min(axis, self.ndim - 1))\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py in _convert_scalar_indexer(self=Index(['PASK_Homo sapiens', 'CSNK2A1_Homo sapien...ens', 'AKT1_Homo sapiens'],\n      dtype='object'), key=0, kind='loc')\n   1280                                               'mixed']:\n   1281                     return self._invalid_indexer('label', key)\n   1282 \n   1283             elif kind in ['loc'] and is_integer(key):\n   1284                 if not self.holds_integer():\n-> 1285                     return self._invalid_indexer('label', key)\n        self._invalid_indexer = <bound method Index._invalid_indexer of Index(['...ns', 'AKT1_Homo sapiens'],\n      dtype='object')>\n        key = 0\n   1286 \n   1287         return key\n   1288 \n   1289     _index_shared_docs['_convert_slice_indexer'] = \"\"\"\n\n...........................................................................\n/home/maayanlab/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py in _invalid_indexer(self=Index(['PASK_Homo sapiens', 'CSNK2A1_Homo sapien...ens', 'AKT1_Homo sapiens'],\n      dtype='object'), form='label', key=0)\n   1464     def _invalid_indexer(self, form, key):\n   1465         \"\"\" consistent invalid indexer message \"\"\"\n   1466         raise TypeError(\"cannot do {form} indexing on {klass} with these \"\n   1467                         \"indexers [{key}] of {kind}\".format(\n   1468                             form=form, klass=type(self), key=key,\n-> 1469                             kind=type(key)))\n        key = 0\n   1470 \n   1471     def get_duplicates(self):\n   1472         from collections import defaultdict\n   1473         counter = defaultdict(lambda: 0)\n\nTypeError: cannot do label indexing on <class 'pandas.core.indexes.base.Index'> with these indexers [0] of <class 'int'>\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "#n_jobs is number of simultaneous processes: seven is about the highest it can go without slowing computer too much or crashing\n",
    "#function iterates over lib2, parallel processing iterates over lib1\n",
    "#p_dicts becomes a list of dicts returned by get_coo_matrix for each Parallel iteration\n",
    "p_dicts = Parallel(n_jobs=7)(delayed(get_coo_matrix)(transformed[lib2], column) for column in transformed[lib1])\n",
    "p_combined_dict = { k: v for d in p_dicts for k, v in d.items() }\n",
    "p_df = pd.DataFrame(index=tformed_libs[feature_lib].columns, columns = tformed_libs[feature_lib].columns)\n",
    "for x in p_combined_dict:\n",
    "\ttf1 = x.partition(',')[0]\n",
    "\ttf2 = x.partition(',')[2]\n",
    "\tp_df.at[tf1,tf2] = p_combined_dict[x]\n",
    "p_df.to_csv(feature_lib.replace('.txt', '') + '_coo_p_vals.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for column in transformed[lib1]:\n",
    "    p_dicts = get_coo_matrix(transformed[lib2], column)\n",
    "    \n",
    "p_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
